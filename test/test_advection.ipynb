{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc254ed-215f-4a78-8ce0-2f168081e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import FieldSet, ParticleSet, AdvectionRK4_3D, ErrorCode, ParticleFile, Field, \\\n",
    "    JITParticle, AdvectionRK4, DiffusionUniformKh, ParcelsRandom, VectorField\n",
    "from parcels.tools.converters import Geographic, GeographicPolar \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from argparse import ArgumentParser\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from sea_clearly import settings\n",
    "from sea_clearly.kernels import unbeaching, delete_particle\n",
    "import pdb\n",
    "\n",
    "from sea_clearly.create_masks import make_landmask,get_coastal_nodes_diagonal,get_shore_nodes_diagonal,create_displacement_field\n",
    "from sea_clearly.write_tools import to_netcdf\n",
    "\n",
    "\n",
    "class Lagrangian_simulation:\n",
    "    \n",
    "    def __init__(self,settings):\n",
    "        self.ufiles = sorted(glob( os.path.join(settings.DIR_INPUT,settings.DIR_UV,settings.PATTERN_U)))\n",
    "        self.vfiles = sorted(glob( os.path.join(settings.DIR_INPUT,settings.DIR_UV,settings.PATTERN_V)))\n",
    "        filenames = {'U': self.ufiles,\n",
    "                     'V': self.vfiles}\n",
    "        self.fieldset = FieldSet.from_netcdf(filenames, settings.VARS, settings.DIMS)\n",
    "        # data_sample_u = xr.load_dataset(self.ufiles[0])\n",
    "        self.lons = self.fieldset.U.lon #data_sample_u['lon'].values\n",
    "        self.lats = self.fieldset.U.lat #data_sample_u['lat'].values\n",
    "        self.fieldset.add_constant('verbose_delete',1)\n",
    "        self.settings = settings \n",
    "        \n",
    "    def set_landmask(self,to_fieldset=False):        \n",
    "        outfile = os.path.join(settings.DIR_INPUT,settings.DIR_UV,settings.NAME_LANDMASK)\n",
    "        if os.path.exists(outfile):\n",
    "            ds = xr.open_dataset(outfile)\n",
    "            self.landmask = np.array(ds['mask_land'],dtype=bool) \n",
    "        else:\n",
    "            self.landmask = make_landmask(self.ufiles[0])\n",
    "            to_netcdf(outfile,[self.landmask],['mask_land'],self.lons,self.lats,explanation='land mask')\n",
    "    \n",
    "        if to_fieldset:\n",
    "            self.fieldset.add_field( Field('landMask',self.landmask,lon=self.lons,lat=self.lats,mesh='spherical') )\n",
    "    \n",
    "    def set_land_displacement(self,mag_u,to_fieldset=True):\n",
    "        outfile = os.path.join(settings.DIR_INPUT,settings.DIR_UV,settings.NAME_LAND_U)\n",
    "        if os.path.exists(outfile):\n",
    "            ds = xr.open_dataset(outfile)\n",
    "            self.u_land = np.array(ds['land_current_u'],dtype=float)    \n",
    "            self.v_land = np.array(ds['land_current_v'],dtype=float)  \n",
    "        else:\n",
    "            self.set_landmask()\n",
    "            self.u_land, self.v_land = create_displacement_field(self.landmask,mag_u)        \n",
    "            to_netcdf(outfile,[self.u_land, self.v_land],['land_current_u','land_current_v'],self.lons,self.lats,explanation='land current, pusing particles on land back to the sea, magnitude of 1')\n",
    "            \n",
    "        if to_fieldset:\n",
    "            U_unbeach = Field('U_unbeach',self.u_land,lon=self.lons,lat=self.lats,fieldtype='U',mesh='spherical')\n",
    "            V_unbeach = Field('V_unbeach',self.v_land,lon=self.lons,lat=self.lats,fieldtype='V',mesh='spherical')\n",
    "            # self.fieldset.add_field(U_unbeach)\n",
    "            # self.fieldset.add_field(V_unbeach)\n",
    "            vectorField_unbeach = VectorField('UV_unbeach',U_unbeach,V_unbeach)\n",
    "            self.fieldset.add_vector_field(vectorField_unbeach)\n",
    "        \n",
    "    def set_turbulent_diffusion(self,K):\n",
    "        K_m = K*np.ones([len(self.lats),len(self.lons)])\n",
    "        K_z = K*np.ones([len(self.lats),len(self.lons)])\n",
    "\n",
    "        Kh_meridional = Field('Kh_meridional', K_m,lon=self.lons,lat=self.lats,mesh='spherical')\n",
    "        Kh_zonal = Field('Kh_zonal', K_z,lon=self.lons,lat=self.lats,mesh='spherical')\n",
    "\n",
    "        self.fieldset.add_field(Kh_meridional)\n",
    "        self.fieldset.add_field(Kh_zonal)\n",
    "        \n",
    "    def set_release(self,date_release):\n",
    "                    \n",
    "        if settings.RELEASE_MODE == 'uniform':\n",
    "            dict_release = settings.DICT_RELEASE\n",
    "            \n",
    "            if dict_release['lon_min'] is None:\n",
    "                dict_release['lon_min'] = min(self.lons)\n",
    "            if dict_release['lon_max'] is None:\n",
    "                dict_release['lon_max'] = max(self.lons)            \n",
    "            if dict_release['lat_min'] is None:\n",
    "                dict_release['lat_min'] = min(self.lats)            \n",
    "            if dict_release['lat_max'] is None:\n",
    "                dict_release['lat_max'] = max(self.lats)    \n",
    "                \n",
    "            lon_release = np.arange(dict_release['lon_min'],dict_release['lon_max'],dict_release['dlon'])\n",
    "            lat_release = np.arange(dict_release['lat_min'],dict_release['lat_max'],dict_release['dlat'])\n",
    "            \n",
    "            \n",
    "            if dict_release['remove_land']:\n",
    "                self.set_landmask()\n",
    "                X_release,Y_release = np.meshgrid(lon_release,lat_release)\n",
    "                mesh_X,mesh_Y = np.meshgrid(self.lons,self.lats)\n",
    "                land_mask_release = griddata((mesh_X.ravel(),mesh_Y.ravel()), self.landmask.ravel(), (X_release,Y_release), method='nearest').astype(bool)\n",
    "\n",
    "                n_particles = len(X_release[~land_mask_release])\n",
    "                lon_release = X_release[~land_mask_release].reshape([n_particles,1])\n",
    "                lat_release = Y_release[~land_mask_release].reshape([n_particles,1])\n",
    "                \n",
    "            self.pset = ParticleSet.from_list(self.fieldset, JITParticle, \n",
    "                                         lon=lon_release,\n",
    "                                         lat=lat_release,\n",
    "                                         time=date_release.to_datetime64())\n",
    "        else:\n",
    "            raise NotImplementedError('Only uniform release implemented for now')\n",
    "        \n",
    "    def set_kernels(self,list_kernels):\n",
    "        self.kernels = self.pset.Kernel(list_kernels[0])\n",
    "        \n",
    "        if len(list_kernels) > 1:\n",
    "            for kernel_ in list_kernels[1:]:\n",
    "                self.kernels += self.pset.Kernel(kernel_)\n",
    "        \n",
    "    def execute(self,date_start,date_end,dt_write,output_filename):\n",
    "        pfile = ParticleFile(os.path.join(settings.DIR_OUTPUT,output_filename), self.pset, outputdt=timedelta(days=dt_write))\n",
    "        \n",
    "        if date_end > date_start:\n",
    "            print('Running forwards simulation...')\n",
    "            dt = timedelta(minutes=20)\n",
    "        else:\n",
    "            print('Running backwards simulation...')\n",
    "            dt = timedelta(minutes=-20)\n",
    "            \n",
    "        runtime = abs(date_end - date_start)\n",
    "        \n",
    "        self.pset.execute(self.kernels,runtime=runtime,dt=dt,output_file=pfile,\n",
    "                          verbose_progress=True,recovery={ErrorCode.ErrorOutOfBounds: delete_particle, ErrorCode.ErrorInterpolation: delete_particle})\n",
    "        \n",
    "        \n",
    "# p = ArgumentParser(description=\"\"\"Parcels runs to construct global transition matrices\"\"\")\n",
    "# p.add_argument('-K_horizontal', '--K_horizontal', default=0, type=float, help='amount of horizontal diffusive mixing [m2/s], 0 for none')\n",
    "# p.add_argument('-date_start', '--date_start', default='2014-01-01-12', type=str, help='Advection starting date')    \n",
    "# p.add_argument('-date_end', '--date_end', default='2015-01-01-12', type=str, help='Advection end date')    \n",
    "# p.add_argument('-dt_write', '--dt_write', default=1, type=float, help='Output dt (keep small for smooth particle simulation plotting)')    \n",
    "# p.add_argument('-u_mag_land', '--u_mag_land', default=1, type=float, help='land current magnitude m/s')    \n",
    "\n",
    "K_horizontal = 0\n",
    "date_start = '2015-01-02'\n",
    "date_end = '2015-06-01'\n",
    "dt_write = 1\n",
    "u_mag_land = 1\n",
    "\n",
    "# args = p.parse_args()\n",
    "\n",
    "date_start = pd.Timestamp(date_start)\n",
    "date_end = pd.Timestamp(date_end)\n",
    "\n",
    "# dt_write = args.dt_write   \n",
    "# K_horizontal = args.K_horizontal\n",
    "# u_mag_land = args.u_mag_land\n",
    "\n",
    "\n",
    "simulation = Lagrangian_simulation(settings)\n",
    "\n",
    "list_kernels = [AdvectionRK4]\n",
    "\n",
    "if u_mag_land > 0:\n",
    "    simulation.set_land_displacement(u_mag_land,to_fieldset=True)\n",
    "    list_kernels.append(unbeaching)\n",
    "\n",
    "if K_horizontal > 0:\n",
    "    simulation.set_turbulent_diffusion(K_horizontal)\n",
    "    list_kernels.append(DiffusionUniformKh)\n",
    "\n",
    "simulation.set_release(date_start)\n",
    "\n",
    "simulation.set_kernels(list_kernels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30ed6b23-b3b6-407d-b932-bf85920fbd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running forwards simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: None: command not found\n",
      "INFO: Compiled ArrayJITParticleAdvectionRK4unbeaching ==> /tmp/parcels-268215/lib8ffe60a9bbd7c85e246d6e6183727f3d_0.so\n",
      "  0%|                                                                                                                            | 0/12960000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particle is deleted out of bounds at lon = -6.0, lat =36.0875, depth =0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 12960000.0/12960000.0 [04:06<00:00, 52606.32it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_filename = 'Test.zarr'\n",
    "simulation.execute(date_start,date_end,dt_write,output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4500f3e-a643-459b-b850-887bca0a8787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed66507e-f166-4eec-8487-5a92dd2d2cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lon_min': -6.0,\n",
       " 'lon_max': 36.291668,\n",
       " 'lat_min': 30.1875,\n",
       " 'lat_max': 45.979168,\n",
       " 'n_gridcell': 2,\n",
       " 'dlon': 0.1,\n",
       " 'dlat': 0.1,\n",
       " 'remove_land': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.RELEASE_MODE\n",
    "settings.DIR_UV\n",
    "\n",
    "os.path.basename(settings.DIR_UV)\n",
    "\n",
    "filename = settings.DIR_UV + settings.RELEASE_MODE\n",
    "settings.DICT_RELEASE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587062c2-ee46-4efb-bf3f-9e8338567f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/shared/oceanparcels/output_data/data_Mikael/SeaClearly/Input/CMEMS_MED/landmask.nc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(settings.DIR_INPUT,'CMEMS_MED',settings.NAME_LANDMASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0df00fb4-2477-4d66-8908-66b7932dcc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CMEMS_MED_uniform_2_pergrid_2015-01-02-00:00:00_2015-06-01-00:00:00_-6.00_36.29_30.19_45.98.zarr'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = ('_'.join([settings.DIR_UV,settings.RELEASE_MODE,'%i_pergrid'%settings.DICT_RELEASE['n_gridcell'],\n",
    "                      str(date_start).replace(' ','-'),str(date_end).replace(' ','-'),\n",
    "                      '%2.2f'%settings.DICT_RELEASE['lon_min'],'%2.2f'%settings.DICT_RELEASE['lon_max'],\n",
    "                      '%2.2f'%settings.DICT_RELEASE['lat_min'],'%2.2f'%settings.DICT_RELEASE['lat_max']])+'.zarr').replace('/','')\n",
    "\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b6fafd2-4680-453b-9005-7d0215b67ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'36.291668'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(settings.DICT_RELEASE['lon_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a05e04ab-94c6-4adf-93d4-8cadbfdb3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start_release = pd.Timestamp('2015-01-01-12')\n",
    "date_end_release = pd.Timestamp('2015-02-01-12')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13072c15-7808-4f67-9f7d-5c6c67892b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2014-01-01 12:00:00')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2015-01-01-12') + timedelta(days=-365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90e16a-4cfc-4196-9022-27e476fc3042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
